Configuration Parameter
hadoop.security.groups.cache.secs=300|2126349562
hadoop.http.max.threads=-1
mapred.child.java.opts=
dfs.replication=1078504339
mapreduce.task.progress-report.interval=0|6000
dfs.checksum.combine.mode=COMPOSITE_CRC
mapreduce.job.reduces=1
mapreduce.jdbc.input.table.name=
dfs.ha.namenodes=
mapred.combiner.class=
dfs.client.block.write.locateFollowingBlock.initial.delay.ms=605858298
mapreduce.job.acl-modify-job=
fs.automatic.close=true
io.map.index.interval=128
mapreduce.task.profile.reduces=0-2
dfs.client.replica.accessor.builder.classes=
hadoop.security.groups.cache.background.reload.threads=3|7456898
fs.local.block.size=33554432|1311230615
mapreduce.input.fileinputformat.list-status.num-threads=1
dfs.client.socketcache.expiryMsec=498378719
mapreduce.input.linerecordreader.line.maxlength=2147483647
hadoop.http.authentication.token.validity=36000
mapreduce.jdbc.input.field.names=
mapreduce.outputcommitter.factory.scheme.hdfs=
hadoop.security.group.mapping=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback
mapreduce.jdbc.input.count.query=
mapreduce.reduce.shuffle.input.buffer.percent=0.70
mapreduce.map.maxattempts=4
hadoop.security.groups.cache.warn.after.ms=5000|1893238533
io.serializations=org.apache.hadoop.io.serializer.WritableSerialization, org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization, org.apache.hadoop.io.serializer.avro.AvroReflectSerialization
hadoop.http.sni.host.check.enabled=false
hadoop.security.auth_to_local.mechanism=hadoop
mapreduce.reduce.shuffle.read.timeout=180000
mapreduce.ifile.readahead.bytes=4194304
mapreduce.cluster.local.dir=/home/tony/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/tmp/mapred/local
hadoop.http.socket.backlog.size=128
fs.foo.impl=
hadoop.prometheus.endpoint.enabled=false
dfs.client.use.datanode.hostname=true
mapreduce.job.name=
mapred.task.maxvmem=-1
dfs.client.read.use.cache.priority=true
dfs.client.refresh.read-block-locations.ms=1441561416
mapreduce.job.local-fs.single-disk-limit.check.interval-ms=5000
mapred.queue.first.acl-administer-jobs=*
mapreduce.job.counters.groups.max=50
dfs.client.mmap.cache.size=2110155848
fs.file.impl.disable.cache=false
io.file.buffer.size=4096
dfs.client.max.block.acquire.failures=2069396912
textinputformat.record.delimiter=
dfs.client.deadnode.detection.enabled=true
dfs.client.retry.interval-ms.get-last-block-length=544350447
dfs.client.datanode-restart.timeout=1792229988
fs.foo.impl.disable.cache=false
dfs.client-write-packet-size=534245248
mapreduce.reduce.shuffle.connect.timeout=180000
yarn.app.mapreduce.client.job.max-retries=3
dfs.client.block.write.retries=757414494
hadoop.security.crypto.jce.provider=
hadoop.security.java.secure.random.algorithm=SHA1PRNG
tmparchives=
yarn.resourcemanager.address=0.0.0.0:8032
mapreduce.job.cache.archives=
file.stream-buffer-size=4096
mapreduce.reduce.maxattempts=4
mapreduce.client.submit.file.replication=10
dfs.client.write.exclude.nodes.cache.expiry.interval.millis=1036791797
fs.hdfs.impl.disable.cache=false
dfs.client.mmap.cache.timeout.ms=1429244908
dfs.namenode.safemode.extension.testing=5236679
dfs.nameservices=
ssl.client.keystore.location=
yarn.app.mapreduce.client.job.retry-interval=2000
hadoop.http.authentication.simple.anonymous.allowed=true
mapreduce.job.end-notification.timeout=5000
file.bytes-per-checksum=512|1268463776
dfs.client.retry.times.get-last-block-length=1623076139
hadoop.security.dns.log-slow-lookups.threshold.ms=1000|326101443
hadoop.security.authentication=simple
mapreduce.job.output.value.class=
mapreduce.task.files.preserve.failedtasks=false
dfs.client.socket-timeout=1224838744
mapreduce.output.fileoutputformat.outputdir=
dfs.client.read.shortcircuit.streams.cache.size=1066197833
mapreduce.job.jvm.numtasks=1
mapreduce.reduce.java.opts=
fs.faildel.impl.disable.cache=false
dfs.datanode.socket.write.timeout=70352633
hadoop.http.max.request.header.size=65536
mapreduce.map.output.value.class=
mapreduce.reduce.shuffle.fetch.retry.interval-ms=1000
oracle.sessionTimeZone=GMT
io.compression.codecs=
mapreduce.job.combine.class=
dfs.nameservice.id=
mapreduce.reduce.shuffle.maxfetchfailures=10
dfs.namenode.support.allow.format=false
mapreduce.reduce.memory.totalbytes=8346664960
mapreduce.jdbc.input.query=
hadoop.ssl.client.conf=ssl-client.xml
mapreduce.cluster.administrators=
mapred.queue.second.acl-administer-jobs=*
mapreduce.job.jar.unpack.pattern=(?:classes/|lib/).*
hadoop.security.groups.cache.background.reload=false
mapreduce.reduce.shuffle.fetch.retry.timeout-ms=30000
hadoop.user.group.static.mapping.overrides=dr.who=;
dfs.bytes-per-checksum=1691875108
mapreduce.map.output.key.class=
dfs.client.cached.conn.retry=1955735718
dfs.client.read.shortcircuit=true
dfs.namenode.lease-hard-limit-sec=1737096012
mapreduce.job.counters.group.name.max=128
hadoop.http.authentication.type=simple
mapreduce.job.log4j-properties-file=
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetTestUtilsFactory=
mapreduce.map.combine.minspills=3
dfs.client.key.provider.cache.expiry=653461201
dfs.datanode.fsdataset.factory=org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetFactory
mapreduce.jdbc.input.class=
dfs.client.failover.sleep.base.millis=624408011
ssl.client.keystore.type=jks
hadoop.http.temp.dir=
mapreduce.reduce.shuffle.max-host-failures=5
dfs.client.socket.send.buffer.size=1723398665
mapreduce.job.hdfs-servers.token-renewal.exclude=
dfs.ha.namenode.id=
dfs.client.hedged.read.threadpool.size=23651328
mapreduce.task.profile.maps=0-2
mapreduce.task.io.sort.factor=10
dfs.client.failover.sleep.max.millis=229884085
fs.permissions.umask-mode=022
mapreduce.reduce.shuffle.notify.readerror=true
mapreduce.job.cache.sharedcache.files.addtoclasspath=
hadoop.http.staticuser.user=dr.who
hdfs.minidfs.basedir=/mnt/batch/tasks/workitems/FUZZ_hdfs_r125_1M24d23h38m7s/job-1/Task102/wd/confuzz/scripts/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs
fs.file.impl=
mapreduce.reduce.ulimit=
mapreduce.job.local.dir=
hadoop.http.authentication.kerberos.keytab=/home/tony/hadoop.keytab
hadoop.tokens=
hadoop.jetty.logs.serve.aliases=true
dfs.client.retry.max.attempts=1831761092
dfs.namenode.maintenance.replication.min=1337357718
dfs.namenode.decommission.interval.testing=1777204884
hadoop.security.auth_to_local=RULE:[1:$1] RULE:[2:$1]
io.compression.codec.bzip2.library=system-native
dfs.client.use.legacy.blockreader.local=true
mapreduce.job.maxtaskfailures.per.tracker=3
dfs.client.retry.window.base=1473650805
dfs.namenode.startup=REGULAR
hadoop.kerberos.keytab.login.autorenewal.enabled=false|true
mapreduce.job.credentials.binary=
mapreduce.job.output.key.comparator.class=
dfs.checksum.ec.socket-timeout=2048525338
fs.creation.parallel.count=2121225290|64
mapreduce.client.output.filter=FAILED
mapreduce.job.cache.limit.max-single-resource-mb=0
dfs.checksum.type=CRC32C
mapreduce.task.uberized=false
dfs.client.read.short.circuit.replica.stale.threshold.ms=147119865
mapreduce.task.profile=false
mapreduce.job.output.key.class=
mapreduce.admin.map.child.java.opts=-Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN
mapred.output.committer.class=
mapreduce.job.jar=
dfs.client.mmap.retry.timeout.ms=1932917247
yarn.app.mapreduce.am.log.level=INFO
hadoop.ssl.keystores.factory.class=org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory
tmpfiles=
mapreduce.job.application.attempt.id=0
hadoop.http.filter.initializers=org.apache.hadoop.http.lib.StaticUserWebFilter
mapreduce.task.io.sort.mb=100
dfs.client.read.shortcircuit.buffer.size=984098379
ipc.client.rpc-timeout.ms=286142237
fs.client.resolve.remote.symlinks=false|true
hadoop.user.group.metrics.percentiles.intervals=
hadoop.ssl.enabled.protocols=TLSv1.2
dfs.domain.socket.path=
mapreduce.task.profile.params=-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s
mapreduce.jdbc.input.conditions=
ssl.server.exclude.cipher.list=
mapreduce.admin.reduce.child.java.opts=-Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN
mapreduce.task.index.cache.limit.bytes=1048576
mapreduce.fileoutputcommitter.cleanup-failures.ignored=false
mapreduce.task.timeout=600000
mapreduce.task.local-fs.write-limit.bytes=-1
mapreduce.fileoutputcommitter.algorithm.version=2
mapreduce.framework.name=yarn|local
mapreduce.reduce.merge.memtomem.threshold=5|10
dfs.client.domain.socket.data.traffic=false
mapreduce.task.local.output.class=
mapreduce.outputcommitter.factory.class=
mapreduce.output.basename=part
dfs.blocksize=766787871
dfs.client.write.byte-array-manager.enabled=false
hadoop.security.dns.log-slow-lookups.enabled=false
mapreduce.job.counters.counter.name.max=64
dfs.web.ugi=
hadoop.http.acceptor.count=-1
hadoop.http.selector.count=-1
fs.hdfs.impl=
dfs.short.circuit.shared.memory.watcher.interrupt.check.ms=1537782846
dfs.domain.socket.disable.interval.seconds=1824286572
mapreduce.job.heap.memory-mb.ratio=0.8
dfs.client.failover.max.attempts=960338182
mapreduce.reduce.merge.memtomem.enabled=false
mapreduce.job.encrypted-intermediate-data=false
dfs.client.read.shortcircuit.streams.cache.expiry.ms=1586719728
mapreduce.job.cache.sharedcache.archives=
mapreduce.client.genericoptionsparser.used=true
dfs.client.read.shortcircuit.metrics.sampling.percentage=1793971948
mapreduce.fileoutputcommitter.failures.attempts=1
hadoop.http.idle_timeout.ms=60000
mapreduce.task.attempt.id=NONMAPREDUCE
dfs.client.read.shortcircuit.skip.checksum=false
mapreduce.job.cache.sharedcache.files=
hadoop.service.shutdown.timeout=30s|30
dfs.client.block.write.locateFollowingBlock.max.delay.ms=2144870084
mapreduce.shuffle.ssl.enabled=false
mapreduce.job.counters.max=120
mapreduce.job.cache.limit.max-resources-mb=0
mapreduce.output.textoutputformat.separator=
dfs.client.mmap.enabled=true
yarn.resourcemanager.ha.enabled=false
mapreduce.reduce.shuffle.merge.percent=0.66
mapred.child.ulimit=
mapreduce.map.ulimit=
dfs.client.hedged.read.threshold.millis=2130074490
dfs.client.write.max-packets-in-flight=828846872
mapreduce.output.fileoutputformat.compress=false
mapreduce.reduce.shuffle.memory.limit.percent=0.25
yarn.nodemanager.recovery.enabled=false
mapreduce.fileoutputcommitter.cleanup.skipped=false
mapreduce.map.output.compress=false
hadoop.security.token.service.use_ip=true
hadoop.kerberos.min.seconds.before.relogin=934143003|60
mapreduce.reduce.input.buffer.percent=0.0
mapreduce.outputcommitter.factory.scheme.faildel=
hadoop.token.files=
mapreduce.task.merge.progress.records=10000
ssl.client.stores.reload.interval=10000
map.sort.class=org.apache.hadoop.util.QuickSort
dfs.client.read.uri.cache.enabled=true
mapreduce.jdbc.username=
mapreduce.reduce.shuffle.retry-delay.max.ms=60000
fs.defaultFS=file:///|hdfs://localhost:42181
mapreduce.client.progressmonitor.pollinterval=1000
mapreduce.job.cache.files=
dfs.client.slow.io.warning.threshold.ms=101556275
dfs.client.block.write.locateFollowingBlock.retries=2100366824
yarn.app.mapreduce.am.staging-dir.erasurecoding.enabled=false
mapreduce.map.sort.spill.percent=0.80
hadoop.security.crypto.cipher.suite=AES/CTR/NoPadding
mapreduce.job.encrypted-intermediate-data.buffer.kb=128
dfs.data.transfer.client.tcpnodelay=true
hadoop.security.crypto.codec.classes.aes.ctr.nopadding=org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec, org.apache.hadoop.crypto.JceAesCtrCryptoCodec
dfs.client.read.prefetch.size=1293404753
hadoop.security.groups.negative-cache.secs=1894143127|30
mapreduce.ifile.readahead=true
mapreduce.task.output.dir=
hadoop.http.authentication.kerberos.principal=HTTP/_HOST@LOCALHOST
hadoop.http.max.response.header.size=65536
tmpjars=
dfs.client.socketcache.capacity=1422534568
mapreduce.job.net.static.resolutions=
dfs.client.short.circuit.num=1767534088
hadoop.http.logs.enabled=true
mapred.queue.second.acl-submit-job=*
hadoop.http.authentication.signature.secret.file=/home/tony/hadoop-http-auth-signature-secret
mapreduce.map.java.opts=
dfs.client.read.striped.threadpool.size=1199708322
mapreduce.job.cache.limit.max-resources=0
